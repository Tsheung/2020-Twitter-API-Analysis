{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Basic Information and Collection of 100 Tweets from Each State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Twython for Twitter API Streaming and collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twython in c:\\users\\toby\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from twython) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from twython) (1.2.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2019.6.16)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\toby\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ",
    "secret = ",
    "token = ",
    "s_token = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twython only requires the use of the key and secret token to access the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "twitter = Twython(key,secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the current Twitter information of Bernie Sanders: name, screen name, profile description, verification check, number of tweets sent out and follower count. I wanted to examine a basis information of each candidate. The show_user function allows the access of examining a certain Twitter user's information. The show_user result is outputted as a json file and using keys like 'name' can access certain information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernie Sanders\n",
      "BernieSanders\n",
      "U.S. Senator from Vermont and candidate for President of the United States.\n",
      "True\n",
      "15998\n",
      "10060162\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "bernie = twitter.show_user(screen_name='BernieSanders')\n",
    "print(bernie['name'])\n",
    "print(bernie['screen_name'])\n",
    "print(bernie['description'])\n",
    "print(bernie['verified'])\n",
    "print(bernie['statuses_count'])\n",
    "print(bernie['followers_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the current Twitter information of Elizabeth Warren: name, screen name, profile description, verification check, number of tweets sent out, follower count. Just like Bernie Sanders' information I wanted to examine the Elizabeth Warren's Twitter statistics and develop a base line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elizabeth Warren\n",
      "ewarren\n",
      "U.S. Senator, former teacher, and candidate for president. Wife, mom (Amelia, Alex, Bailey, @CFPB), grandmother, and Okie. She/her. Official campaign account.\n",
      "True\n",
      "7255\n",
      "3525140\n"
     ]
    }
   ],
   "source": [
    "warren = twitter.show_user(screen_name='ewarren')\n",
    "print(warren['name'])\n",
    "print(warren['screen_name'])\n",
    "print(warren['description'])\n",
    "print(warren['verified'])\n",
    "print(warren['statuses_count'])\n",
    "print(warren['followers_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the current Twitter information of Joe Biden: name, screen name, profile description, verification check, number of tweets sent out, follower count.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden\n",
      "JoeBiden\n",
      "Senator, Vice President, 2020 candidate for President of the United States, husband to @DrBiden, proud father & grandfather. Loves ice cream, aviators & @Amtrak\n",
      "True\n",
      "3309\n",
      "3993161\n"
     ]
    }
   ],
   "source": [
    "biden = twitter.show_user(screen_name='JoeBiden')\n",
    "print(biden['name'])\n",
    "print(biden['screen_name'])\n",
    "print(biden['description'])\n",
    "print(biden['verified'])\n",
    "print(biden['statuses_count'])\n",
    "print(biden['followers_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examination of Bernie Sander's most recent Tweet. I believe that examine the most recent tweet can develop a base line of understand of how many people liked the tweet, retweets, what the tweet was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Dec 08 17:16:15 +0000 2019',\n",
       " 'id': 1203724984692215809,\n",
       " 'id_str': '1203724984692215809',\n",
       " 'text': 'RT @SenGianaris: “Amazon is taking the space without any ... special tax credits and other inducements”\\n\\nSo about that $3 billion... https:…',\n",
       " 'truncated': False,\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [{'screen_name': 'SenGianaris',\n",
       "    'name': 'Sen. Mike Gianaris',\n",
       "    'id': 319785911,\n",
       "    'id_str': '319785911',\n",
       "    'indices': [3, 15]}],\n",
       "  'urls': []},\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'retweeted_status': {'created_at': 'Fri Dec 06 22:34:56 +0000 2019',\n",
       "  'id': 1203080408587526144,\n",
       "  'id_str': '1203080408587526144',\n",
       "  'text': '“Amazon is taking the space without any ... special tax credits and other inducements”\\n\\nSo about that $3 billion... https://t.co/JbJ8RGGbDt',\n",
       "  'truncated': False,\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'user_mentions': [],\n",
       "   'urls': [{'url': 'https://t.co/JbJ8RGGbDt',\n",
       "     'expanded_url': 'https://www.wsj.com/articles/amazon-leases-new-manhattan-office-space-less-than-a-year-after-hq2-pullout-11575671243',\n",
       "     'display_url': 'wsj.com/articles/amazo…',\n",
       "     'indices': [116, 139]}]},\n",
       "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'retweet_count': 166,\n",
       "  'favorite_count': 793,\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'lang': 'en'},\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 166,\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examination of Elizabeth Warren's most recent Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Dec 01 17:27:30 +0000 2019',\n",
       " 'id': 1201191102260371457,\n",
       " 'id_str': '1201191102260371457',\n",
       " 'text': 'The people of Chicago are fired up for big, structural change. And I promise: As president, I’ll fight for your fam… https://t.co/miBlb1RWXs',\n",
       " 'truncated': True,\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [{'url': 'https://t.co/miBlb1RWXs',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1201191102260371457',\n",
       "    'display_url': 'twitter.com/i/web/status/1…',\n",
       "    'indices': [117, 140]}]},\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 112,\n",
       " 'favorite_count': 698,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warren['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examination of Joe Biden's most recent tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sun Dec 08 15:34:25 +0000 2019',\n",
       " 'id': 1203699359914872832,\n",
       " 'id_str': '1203699359914872832',\n",
       " 'text': 'I’m glad the Senate passed the #FUTUREAct to permanently fund historically black colleges and universities, and oth… https://t.co/HStdYMLacP',\n",
       " 'truncated': True,\n",
       " 'entities': {'hashtags': [{'text': 'FUTUREAct', 'indices': [31, 41]}],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [{'url': 'https://t.co/HStdYMLacP',\n",
       "    'expanded_url': 'https://twitter.com/i/web/status/1203699359914872832',\n",
       "    'display_url': 'twitter.com/i/web/status/1…',\n",
       "    'indices': [117, 140]}]},\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': True,\n",
       " 'quoted_status_id': 1202790277792047104,\n",
       " 'quoted_status_id_str': '1202790277792047104',\n",
       " 'retweet_count': 223,\n",
       " 'favorite_count': 1171,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every cell below is the collection of tweets by geotags per state. I used the geotags from this website which specified which each state's geotags. https://www.latlong.net/category/states-236-14.html \n",
    "Below is my first use of capturing 100 tweets from Wisconsin and I wanted to examine the tweets to see if it worked. I captured 100 tweets for each state and below is my code. I placed each states' tweets into separate json files with the abbreviations as their filename. I believe that there probably was a smarter way to do it but I was a foolish novice in collecting Twitter data. \n",
    "\n",
    "Warning: if the cell are run again, possible duplications to the project directory might be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "@JoeBiden So you’ve never heard of 2019?\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@ylanmui @crampell @JoeBiden @JohnJHarwood Could you spell out what Bernie and Warren's plans would do to the economy.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@likeabaroness @ewarren @SharylAttkisson Just keep it up. We don't want you to stop. Anyone who has an opinion that… https://t.co/Vq2sE1MYvi\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren Yeah. What Bernie Sanders said...\n",
      "Northwoods of Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@HavokRayne @emalyculich @StormCrownSr @GHicks81 @ScarletElenti @BernieSanders Guess I misswd the class where they… https://t.co/jubwqQnQKc\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@rickyb_sports @ewarren @SharylAttkisson This is a mild fucking comment compared to what Trump voters say but appar… https://t.co/HYbezFNW4b\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@C_butter @ewarren @amyklobuchar @JoeBiden Agreed\n",
      "northern wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@likeabaroness @ewarren @SharylAttkisson People like you are exactly why Trump won and will win again.\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@LibraProtocol @BernieSanders Actually their emissions are about half of ours. https://t.co/GGnEOreX1S\n",
      "MN/WI\n",
      "\n",
      "\n",
      "None\n",
      "@luttydaddy @john_sipher @aubrey_huff @BernieSanders @realDonaldTrump @NRA @WatchChad Truth!\n",
      "northern wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden How much are they Joe? https://t.co/IsHm9N249X\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden https://t.co/FMCv3tfwaE\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren You're rich and powerful Liz. Is that why I don't believe a word you say?\n",
      "Or is it that you sold out your… https://t.co/KRKrQnEFhH\n",
      "Northwoods of Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Maybe we can just our kids a job at Burisma\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@R3DF0X0N3 @ewarren How about the creation of the CFPB before she even became a Senator?\n",
      "\n",
      "Also lmao she's a Senator… https://t.co/uAVzytTeni\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@TerryLeeHummel @ewarren what?\n",
      "\n",
      "did she not just list a bunch of shit he promised but didn't do?\n",
      "\n",
      "do you have proof… https://t.co/lyNGR8RBed\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@ananavarro @JoeBiden @SpeakerPelosi @HillaryClinton https://t.co/I3GfxRBHkx\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Please quit touching random women. DO NOT TOUCH. Anywhere. Not face, arms, head, back, etc. This is not 1… https://t.co/BB9LInXf1i\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@Hansen4Congress @BernieSanders @GretaThunberg Just when you think they cant stoop any ‘lower’!!! 🤔🧐🤢💪🏼\n",
      "USA, WI \n",
      "\n",
      "\n",
      "None\n",
      "@geoplanetary @Siberyn3 @TidePride8 @JoeBiden @TheLionsDen18 He got a new one appointed by getting the other one fi… https://t.co/4m9hOcCCfr\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren Earning the nickname \"EDizzyBeth\" again, I see.\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden @JohnKerry https://t.co/4p6Doqpqul\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@justicedems @AOC @JoeBiden C'mon man...divine right of kings, am I right?\n",
      "Wausau, WI\n",
      "\n",
      "\n",
      "None\n",
      "@geoplanetary @Siberyn3 @TidePride8 @JoeBiden @TheLionsDen18 Okay so if that was wrong then the Russian investigati… https://t.co/zU9DRcAFt5\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Dignity?\n",
      "\n",
      "Ok... so make that connection to a kid getting appointed to a position he was in no way qualifi… https://t.co/hyC45KFehq\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@tomselliott @JoeBiden ...that no president has ever done...\n",
      "\n",
      "He must be referring to uncovering a treasonous deep… https://t.co/0AyTk81u2G\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @ana_hunsicker: @Hansen4Congress @JoeBiden @realDonaldTrump He gets More &amp; More Ridiculous Every Day!!! 🙈💪🏼..Lord Help us with ‘that’ on…\n",
      "GOV of Georgia♥️ Janny Cares\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren I'll put whatever you say right in there with Obama. \n",
      "Lying POS that won't do a thing you campaigned on,… https://t.co/KfH6ZyJf9h\n",
      "Northwoods of Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "RT @rickyb_sports: @ewarren @SharylAttkisson Trump has kept more of his campaign promises than any other prez in my lifetime. He's done exa…\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren @SharylAttkisson Trump has kept more of his campaign promises than any other prez in my lifetime. He's don… https://t.co/2fEK80aUXD\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Breaking Joe Biden at it again..... https://t.co/DaUGpOMTY2\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden https://t.co/qpEl03s8Fc\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@ScottFordTVGuy @ewarren Makes sense when you want to get into a prestigious college, which she did.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@geoplanetary @Siberyn3 @TidePride8 @JoeBiden @TheLionsDen18 lol because Biden got a new prosecutor appointed . One… https://t.co/kr5K5bPZJy\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @JayChpJones: @320Revelation @Tess3761 @Elvis21211 @JoeBiden https://t.co/U7nprKsTh8\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "@Hansen4Congress @JoeBiden @realDonaldTrump He gets More &amp; More Ridiculous Every Day!!! 🙈💪🏼..Lord Help us with ‘tha… https://t.co/vfSk0ghi3S\n",
      "USA, WI \n",
      "\n",
      "\n",
      "None\n",
      "@HavokRayne @emalyculich @StormCrownSr @GHicks81 @ScarletElenti @BernieSanders Lol what??\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@Siberyn3 @TidePride8 @JoeBiden @TheLionsDen18 There’s literally a video of Biden withholding a billion dollars to… https://t.co/7hTU1GCZWP\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@Siberyn3 @TidePride8 @JoeBiden @TheLionsDen18 There’s no evidence because there hasn’t been an investigation, but… https://t.co/iWVLkaq7RX\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders #3: https://t.co/Y8eGcEukLu\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@drbashir2018 @Cmm09672 @ewarren @TheSWPrincess @jomareewade @TaoOfPooh @AdaKirschner @B52Malmet @Boba_Tea_Catan… https://t.co/S1o49puiDH\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@drbashir2018 @Cmm09672 @ewarren @TheSWPrincess @jomareewade @TaoOfPooh @AdaKirschner @B52Malmet @Boba_Tea_Catan… https://t.co/kL8bh6Y9Us\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@Reuters Try em on, Fellas. @JohnKerry @JoeBiden https://t.co/zaHnRPUfKf\n",
      "SE WI\n",
      "\n",
      "\n",
      "None\n",
      "RT @CJSzafir: .@ewarren basically just told low-income Milwaukee parents that - rather than use school choice - their kids should be forced…\n",
      "Menomonee Falls, Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden We have the lowest unemployment in decades. What are you talking about. Maybe you should talk to constitu… https://t.co/pcnZWJXrYp\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders I love you Bernie. All I want is for you to get a fair chance at becoming our leader. I'll support you until the end.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders every single time!!!\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "{'id': '7dc5c6d3bfb10ccc', 'url': 'https://api.twitter.com/1.1/geo/id/7dc5c6d3bfb10ccc.json', 'place_type': 'admin', 'name': 'Wisconsin', 'full_name': 'Wisconsin, USA', 'country_code': 'US', 'country': 'United States', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-92.889433, 42.491921], [-86.24955, 42.491921], [-86.24955, 47.309715], [-92.889433, 47.309715]]]}, 'attributes': {}}\n",
      "@JoeBiden Is that what you told Corn Pop?\n",
      "Huntley, IL\n",
      "\n",
      "\n",
      "None\n",
      "@EdPedro7 @BernieSanders Nobody is saying to stop all climate change, just the man made climate change.\n",
      "MN/WI\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders only reason u political hacks support abortion is for the money if it were about woman rights to the… https://t.co/xoNScmdFM4\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@LibraProtocol @BernieSanders Do you know how much CO2 India emits relative to us?\n",
      "MN/WI\n",
      "\n",
      "\n",
      "None\n",
      "@DaleL_McDowell @ARCartoons @BernieSanders Scientists are almost entirely certain that people are to blame.\n",
      "MN/WI\n",
      "\n",
      "\n",
      "None\n",
      "@Liz_Wheeler @BernieSanders “Changing the weather” is a terribly misleading way of putting it.\n",
      "MN/WI\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden @LindaKWS1 Absolutely Right!\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Sure in the hell is not your, your the laughing boy, touchy feeling joe, my long hair gets rubbed, your s… https://t.co/0GwqILvqYo\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@SpringSteps @BernieSanders So are the 103K likes. 😞\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden He stupifies the nation. Exposing it to daily doses of moron. https://t.co/3SALvWaGkF\n",
      "Southeastern Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@RobynGruner @BernieSanders Well said.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "I might vote for @BernieSanders just so he crashes the system and we can start over.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@PatriotsArmy2 @MAGA2ARIGHTS @JoeBiden Joe Biden: \"Get off my lawn!!\"\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@jmartNYT @maggieNYT @BernieSanders Typical anti-Biden tweet from you. Retweeted by @maggieNYT, of course.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Release them now. It's legal.  Make them fight.  What does this man have to hide?  Think of the book and… https://t.co/mwPNW4XBaQ\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren Your goal is to become \"a two-bit dictator\"? 🤔\n",
      "Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden What do you mean? President Trump has the economy booming. Lowest unemployment in 50 years (as long as yo… https://t.co/EEITiykDzb\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders Right now!\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Yeah Joe, now go take a pill.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@DanielAshley13 @ewarren Lmao\n",
      "wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren Politicize this.  Brilliance.  Wonder why you don’t stand a chance?  Didn’t think so. Keep pissing away yo… https://t.co/qYdPCKzUB9\n",
      "wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@Lauren_Steiner @BernieSanders I don't think he does all his own tweets. Do you?\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@themaxburns @ewarren Sinclair. That says it all.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders Appalling- killing an unborn baby is not a right\n",
      "Up North, Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Joe doesn't talk like that a) he gets flustered &amp; forgets what he is saying b) he has no compassion for the American family\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden What a stupid post, a job is about responsibility. I don't know anyone that gets a job to feel worthy. You've lost it Biden\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@Joseph50128487 @lunibin @MMerkington @BernieSanders Predictably lazy\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Democrats, like me, ARE down for Medicare for all and for free public college and for child care assistan… https://t.co/Lqpo7gaLdl\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @CJSzafir: .@ewarren basically just told low-income Milwaukee parents that - rather than use school choice - their kids should be forced…\n",
      "Nebraska, USA\n",
      "\n",
      "\n",
      "None\n",
      "@ewarren Then let our war fighters be armed, if you’re so heartsick. This happens in gun free zones 98% of the time… https://t.co/YIHypEGcLU\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @Captain_Anus: @Lis_Smith @ewarren I am in Wisconsin and I do not want to vote foe Pete. Warren and Sanders are better than Pete\n",
      "Pittsburgh, Pennsylvania\n",
      "\n",
      "\n",
      "None\n",
      "@ChristopherHahn @JoeBiden @PeteButtigieg Wow....this is the first thing I’ve seen you tweet that I agree with.  I’m stunned lol\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@DackRouleau @BernieSanders Some staffer tweeted that in February 2018  and you are just seeing it now?!?!\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@AkeemCrain @JoeBiden Lol true..\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@SKYRIDER4538 @debbra_mckay @JoeBiden @carrerapulse We want a video of your pushups #QuidProJoe\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden That isn't you patsy.\n",
      "Great State of Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders Cult of death. \n",
      "\n",
      "Time to evaluate your life.\n",
      "Great State of Wisconsin\n",
      "\n",
      "\n",
      "None\n",
      "RT @ana_hunsicker: @Hansen4Congress @SenateGOP @BarackObama @RepAdamSchiff @JoeBiden @HunterBiden @AlexandraChalup @NellieOhr Let’s let ALL…\n",
      "Ohio, USA\n",
      "\n",
      "\n",
      "None\n",
      "@BernieSanders You left out Spectrum. One cannot get affordable Internet service without \"bundling\" with equally un… https://t.co/BlksB1Lg5C\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @ZL1_RyJax: @bahamamills @FKUJAK1 Yep legal citizen asks @JoeBiden a question &amp; crazy joe goes off! Insults the guy, challenged him to a…\n",
      "Maryland, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @ana_hunsicker: @Hansen4Congress @SenateGOP @BarackObama @RepAdamSchiff @JoeBiden @HunterBiden @AlexandraChalup @NellieOhr Let’s let ALL…\n",
      "Mückenhausen\n",
      "\n",
      "\n",
      "None\n",
      "@AlxThomp @maggieNYT Actually I can relate to @ewarren  backstory. Our mom grew up in Ft Yates ND which is Tribal H… https://t.co/wi7UU97dBB\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden In the richest country in the world, no family should be unable to afford a record player.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @Captain_Anus: @Lis_Smith @ewarren I am in Wisconsin and I do not want to vote foe Pete. Warren and Sanders are better than Pete\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Nice try Joe. Everyone knows your nothing but a career politician thats for sale to the highest bidder.\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden 🤣😂🤣😂\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "{'id': '7dc5c6d3bfb10ccc', 'url': 'https://api.twitter.com/1.1/geo/id/7dc5c6d3bfb10ccc.json', 'place_type': 'admin', 'name': 'Wisconsin', 'full_name': 'Wisconsin, USA', 'country_code': 'US', 'country': 'United States', 'contained_within': [], 'bounding_box': {'type': 'Polygon', 'coordinates': [[[-92.889433, 42.491921], [-86.24955, 42.491921], [-86.24955, 47.309715], [-92.889433, 47.309715]]]}, 'attributes': {}}\n",
      "@BernieSanders 💯\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "RT @ana_hunsicker: @Hansen4Congress @SenateGOP @BarackObama @RepAdamSchiff @JoeBiden @HunterBiden @AlexandraChalup @NellieOhr Let’s let ALL…\n",
      "\n",
      "\n",
      "\n",
      "None\n",
      "@JoeBiden Then Democrats wedge issue will be gone, they won’t have it .\n",
      "Wisconsin, USA\n",
      "\n",
      "\n",
      "None\n",
      "RT @BillDargel: @BernieSanders Abortion is not a constitutional right but the right of the people to keep and bear arms is.\n",
      " So when is our…\n",
      "Chicago, IL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('WI.json', 'r') as my_file:\n",
    "    data_json = my_file.read()\n",
    "    wi = json.loads(data_json)\n",
    "    \n",
    "#pprint(all)\n",
    "k = 0\n",
    "\n",
    "for i in wi['WI']:\n",
    "    #pprint(i)\n",
    "    #print(['WI'][k])\n",
    "    print(i['place'])\n",
    "    print(i['text'])\n",
    "    print(i['user']['location'])\n",
    "    print('\\n')\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter search function allows the query (q) for all three candidates and the or specifies that the text can contain either candidate or several. The type is allowing whether or not the tweets are both popular and recent tweets. The count specifies how many tweets should be collected. I chose 100 for each state. The geocode is the coordinate for each state and I allowed a 50 mile radius from that geotag.  \n",
    "\n",
    "The tweets['status'] is what the information's key is placed under. I appended all of the information to a dictionary with the key as the state abbreviation and the values as the tweet status aka its information. Below I repeated this process for 50 times for each state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#West Virginia \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.000000,-80.500000,50mi')\n",
    "all = candidates['statuses']\n",
    "WestVirg = {}\n",
    "WestVirg['WV'] = all\n",
    "\n",
    "#with open('WV.json', 'w') as my_file:\n",
    "#    data_json = json.dumps(WestVirg)\n",
    "#    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vermont\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.000000,-72.699997,50mi')\n",
    "all = candidates['statuses']\n",
    "Vermont = {}\n",
    "Vermont['VT'] = all\n",
    "\n",
    "\n",
    "with open('VT.json', 'w') as my_file:\n",
    "    data_json = json.dumps(Vermont)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Texas,\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='31.000000,-100.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "Texas = {}\n",
    "Texas['TX'] = all\n",
    "\n",
    "\n",
    "with open('TX.json', 'w') as my_file:\n",
    "    data_json = json.dumps(Texas)\n",
    "    my_file.write(data_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South Dakota\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.500000,-100.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "SouthDok = {}\n",
    "SouthDok['SD'] = all\n",
    "\n",
    "\n",
    "with open('SD.json', 'w') as my_file:\n",
    "    data_json = json.dumps(SouthDok)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rhode Island \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='41.700001,-71.500000,50mi')\n",
    "all = candidates['statuses']\n",
    "Rhode = {}\n",
    "Rhode['RI'] = all\n",
    "\n",
    "\n",
    "with open('RI.json', 'w') as my_file:\n",
    "    data_json = json.dumps(Rhode)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oregon\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.000000,-120.500000,50mi')\n",
    "all = candidates['statuses']\n",
    "Oregon = {}\n",
    "Oregon['OR'] = all\n",
    "\n",
    "\n",
    "with open('OR.json', 'w') as my_file:\n",
    "    data_json = json.dumps(Oregon)\n",
    "    my_file.write(data_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New York\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='43.000000,-75.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "newyork = {}\n",
    "newyork['NY'] = all\n",
    "\n",
    "\n",
    "with open('NY.json', 'w') as my_file:\n",
    "    data_json = json.dumps(newyork)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Hampshire\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.000000,-71.500000,50mi')\n",
    "all = candidates['statuses']\n",
    "newhamp = {}\n",
    "newhamp['NH'] = all\n",
    "\n",
    "\n",
    "with open('NH.json', 'w') as my_file:\n",
    "    data_json = json.dumps(newhamp)\n",
    "    my_file.write(data_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nebraska \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='41.500000,-100.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "nebraska = {}\n",
    "nebraska['NE'] = all\n",
    "\n",
    "\n",
    "with open('NE.json', 'w') as my_file:\n",
    "    data_json = json.dumps(nebraska)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kansas\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='38.500000,-98.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "kansas = {}\n",
    "kansas['KS'] = all\n",
    "\n",
    "\n",
    "with open('KS.json', 'w') as my_file:\n",
    "    data_json = json.dumps(kansas)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mississippi\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='33.000000,-90.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "miss = {}\n",
    "miss['MS'] = all\n",
    "\n",
    "\n",
    "with open('MS.json', 'w') as my_file:\n",
    "    data_json = json.dumps(miss)\n",
    "    my_file.write(data_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Illinois\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='40.000000,-89.000000,50mi')\n",
    "all = candidates['statuses']\n",
    "ill = {}\n",
    "ill['IL'] = all\n",
    "\n",
    "\n",
    "with open('IL.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ill)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delaware\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.000000,-75.500000,50mi')\n",
    "all = candidates['statuses']\n",
    "dela = {}\n",
    "dela['DE'] = all\n",
    "\n",
    "\n",
    "with open('DE.json', 'w') as my_file:\n",
    "    data_json = json.dumps(dela)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecticut\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='41.599998,-72.699997,50mi')\n",
    "all = candidates['statuses']\n",
    "connect = {}\n",
    "connect['CT'] = all\n",
    "\n",
    "\n",
    "with open('CT.json', 'w') as my_file:\n",
    "    data_json = json.dumps(connect)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arkansas\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='34.799999,-92.199997,50mi')\n",
    "all = candidates['statuses']\n",
    "ark = {}\n",
    "ark['AR'] = all\n",
    "\n",
    "\n",
    "with open('AR.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ark)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indiana\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='40.273502,-86.126976,50mi')\n",
    "all = candidates['statuses']\n",
    "ind = {}\n",
    "ind['IN'] = all\n",
    "\n",
    "\n",
    "with open('IN.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ind)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missouri\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='38.573936,-92.603760,50mi')\n",
    "all = candidates['statuses']\n",
    "missouri = {}\n",
    "missouri['MO'] = all\n",
    "\n",
    "\n",
    "with open('MO.json', 'w') as my_file:\n",
    "    data_json = json.dumps(missouri)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Florida\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='27.994402,-81.760254,50mi')\n",
    "all = candidates['statuses']\n",
    "flor = {}\n",
    "flor['FL'] = all\n",
    "\n",
    "\n",
    "with open('FL.json', 'w') as my_file:\n",
    "    data_json = json.dumps(flor)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nevada \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.876019,-117.224121,50mi')\n",
    "all = candidates['statuses']\n",
    "nev = {}\n",
    "nev['NV'] = all\n",
    "\n",
    "\n",
    "with open('NV.json', 'w') as my_file:\n",
    "    data_json = json.dumps(nev)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maine\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='45.367584,-68.972168,50mi')\n",
    "all = candidates['statuses']\n",
    "maine = {}\n",
    "maine['ME'] = all\n",
    "\n",
    "\n",
    "with open('ME.json', 'w') as my_file:\n",
    "    data_json = json.dumps(maine)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Michigan\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.182205,-84.506836,50mi')\n",
    "all = candidates['statuses']\n",
    "mich = {}\n",
    "mich['MI'] = all\n",
    "\n",
    "\n",
    "with open('MI.json', 'w') as my_file:\n",
    "    data_json = json.dumps(mich)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Georgia\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='33.247875,-83.441162,50mi')\n",
    "all = candidates['statuses']\n",
    "geo = {}\n",
    "geo['GA'] = all\n",
    "\n",
    "\n",
    "with open('GA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(geo)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hawaii\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='20.716179,-158.214676,50mi')\n",
    "all = candidates['statuses']\n",
    "hawa = {}\n",
    "hawa['HI'] = all\n",
    "\n",
    "\n",
    "with open('HI.json', 'w') as my_file:\n",
    "    data_json = json.dumps(hawa)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, Alaska was the only state that could not collect Tweets from that mentioned Joe Biden, Elizabeth Warren or Bernie Sanders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Alaska\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='66.160507,-153.369141,100mi')\n",
    "all = candidates['statuses']\n",
    "alas = {}\n",
    "alas['AK'] = all\n",
    "\n",
    "print(all)\n",
    "#with open('AK.json', 'w') as my_file:\n",
    "#    data_json = json.dumps(alas)\n",
    "#    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tennessee\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='35.860119,-86.660156,50mi')\n",
    "all = candidates['statuses']\n",
    "tenn = {}\n",
    "tenn['TN'] = all\n",
    "\n",
    "\n",
    "with open('TN.json', 'w') as my_file:\n",
    "    data_json = json.dumps(tenn)\n",
    "    my_file.write(data_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Virgina \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='37.926868,-78.024902,50mi')\n",
    "all = candidates['statuses']\n",
    "virgina = {}\n",
    "virgina['VA'] = all\n",
    "\n",
    "\n",
    "with open('VA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(virgina)\n",
    "    my_file.write(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Jersey \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='37.926868,-78.024902,50mi')\n",
    "all = candidates['statuses']\n",
    "jers = {}\n",
    "jers['NJ'] = all\n",
    "\n",
    "\n",
    "with open('NJ.json', 'w') as my_file:\n",
    "    data_json = json.dumps(jers)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kentucky \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='37.839333,-84.270020,50mi')\n",
    "all = candidates['statuses']\n",
    "kent = {}\n",
    "kent['KY'] = all\n",
    "\n",
    "\n",
    "with open('KY.json', 'w') as my_file:\n",
    "    data_json = json.dumps(kent)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Dakota\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='47.650589,-100.437012,50mi')\n",
    "all = candidates['statuses']\n",
    "northdak = {}\n",
    "northdak['ND'] = all\n",
    "\n",
    "\n",
    "with open('ND.json', 'w') as my_file:\n",
    "    data_json = json.dumps(northdak)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minnesota\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='46.392410,-94.636230,50mi')\n",
    "all = candidates['statuses']\n",
    "minn = {}\n",
    "minn['MN'] = all\n",
    "\n",
    "\n",
    "with open('MN.json', 'w') as my_file:\n",
    "    data_json = json.dumps(minn)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oklahoma\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='36.084621,-96.921387,50mi')\n",
    "all = candidates['statuses']\n",
    "okla = {}\n",
    "okla['OK'] = all\n",
    "\n",
    "\n",
    "with open('OK.json', 'w') as my_file:\n",
    "    data_json = json.dumps(okla)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montana\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='46.965260,-109.533691,50mi')\n",
    "all = candidates['statuses']\n",
    "mont = {}\n",
    "mont['MT'] = all\n",
    "\n",
    "\n",
    "with open('MT.json', 'w') as my_file:\n",
    "    data_json = json.dumps(mont)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Washington\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='47.751076,-120.740135,50mi')\n",
    "all = candidates['statuses']\n",
    "wash = {}\n",
    "wash['WA'] = all\n",
    "\n",
    "\n",
    "with open('WA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(wash)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utah\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.419220,-111.950684,50mi')\n",
    "all = candidates['statuses']\n",
    "utah = {}\n",
    "utah['UT'] = all\n",
    "\n",
    "\n",
    "with open('UT.json', 'w') as my_file:\n",
    "    data_json = json.dumps(utah)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colorado\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.113014,-105.358887,50mi')\n",
    "all = candidates['statuses']\n",
    "colo = {}\n",
    "colo['CO'] = all\n",
    "\n",
    "\n",
    "with open('CO.json', 'w') as my_file:\n",
    "    data_json = json.dumps(colo)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ohio\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='40.367474,-82.996216,50mi')\n",
    "all = candidates['statuses']\n",
    "ohio = {}\n",
    "ohio['OH'] = all\n",
    "\n",
    "\n",
    "with open('OH.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ohio)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alabama\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='32.318230,-86.902298,50mi')\n",
    "all = candidates['statuses']\n",
    "alabama = {}\n",
    "alabama['AL'] = all\n",
    "\n",
    "\n",
    "with open('AL.json', 'w') as my_file:\n",
    "    data_json = json.dumps(alabama)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iowa\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='42.032974,-93.581543,50mi')\n",
    "all = candidates['statuses']\n",
    "iowa = {}\n",
    "iowa['IA'] = all\n",
    "\n",
    "\n",
    "with open('IA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(iowa)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Mexico\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='34.307144,-106.018066,50mi')\n",
    "all = candidates['statuses']\n",
    "mex = {}\n",
    "mex['NM'] = all\n",
    "\n",
    "\n",
    "with open('NM.json', 'w') as my_file:\n",
    "    data_json = json.dumps(mex)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#South Carolina \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='33.836082,-81.163727,50mi')\n",
    "all = candidates['statuses']\n",
    "scaro = {}\n",
    "scaro['SC'] = all\n",
    "\n",
    "\n",
    "with open('SC.json', 'w') as my_file:\n",
    "    data_json = json.dumps(scaro)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PA\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='41.203323,-77.194527,50mi')\n",
    "all = candidates['statuses']\n",
    "penn = {}\n",
    "penn['PA'] = all\n",
    "\n",
    "\n",
    "with open('PA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(penn)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arizona\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='34.048927,-111.093735,50mi')\n",
    "all = candidates['statuses']\n",
    "ari = {}\n",
    "ari['AZ'] = all\n",
    "\n",
    "\n",
    "with open('AZ.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ari)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maryland\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='39.045753,-76.641273,50mi')\n",
    "all = candidates['statuses']\n",
    "mary = {}\n",
    "mary['MD'] = all\n",
    "\n",
    "\n",
    "with open('MD.json', 'w') as my_file:\n",
    "    data_json = json.dumps(mary)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Massachusettes\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='42.407211,-71.382439,50mi')\n",
    "all = candidates['statuses']\n",
    "mass = {}\n",
    "mass['MA'] = all\n",
    "\n",
    "\n",
    "with open('MA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(mass)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idaho\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='44.068203,-114.742043,50mi')\n",
    "all = candidates['statuses']\n",
    "ida = {}\n",
    "ida['ID'] = all\n",
    "\n",
    "\n",
    "with open('ID.json', 'w') as my_file:\n",
    "    data_json = json.dumps(ida)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAlifornia\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='36.778259,-119.417931,50mi')\n",
    "all = candidates['statuses']\n",
    "cali = {}\n",
    "cali['CA'] = all\n",
    "\n",
    "\n",
    "with open('CA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(cali)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wyoming\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='43.075970,-107.290283,50mi')\n",
    "all = candidates['statuses']\n",
    "wyom = {}\n",
    "wyom['WY'] = all\n",
    "\n",
    "\n",
    "with open('WY.json', 'w') as my_file:\n",
    "    data_json = json.dumps(wyom)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#North Carolina \n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='35.782169,-80.793457,50mi')\n",
    "all = candidates['statuses']\n",
    "northca = {}\n",
    "northca['NC'] = all\n",
    "\n",
    "\n",
    "with open('NC.json', 'w') as my_file:\n",
    "    data_json = json.dumps(northca)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Louisiana\n",
    "candidates = twitter.search(q = '@BernieSanders OR @ewarren OR @JoeBiden', type = 'mixed', count = 100, geocode='30.391830,-92.329102,50mi')\n",
    "all = candidates['statuses']\n",
    "louis = {}\n",
    "louis['LA'] = all\n",
    "\n",
    "\n",
    "with open('LA.json', 'w') as my_file:\n",
    "    data_json = json.dumps(louis)\n",
    "    my_file.write(data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the states' 100 tweets are appended into separate json files with their abbreviation name.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze each States' Tweets and into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the creation of a pandas dataframe and believe that a table of information is helpful to understand the number of tweets by state for each candidate. Each row is the state abbreviation and candidate name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Sanders</th>\n",
       "      <th>Warren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [State, Biden, Sanders, Warren]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col = ['State', 'Biden','Sanders', 'Warren']\n",
    "df = pd.DataFrame(columns = col)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creation of a list containing each filename for the state tweet information will be helpful to use a function with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ['AK', 'AL', 'AR', 'AZ', 'CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function called input_state that takes the input of the filename and num will keep a count for the index within the pandas dataframe. The function loads the file and creates a count for each candidate that starts with zero. As each tweet tweet contains a certain candidates' name as a tag, the count will increment. The total count for each candidate will then be appended to the pandas dataframe as a row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_state(state, num):\n",
    "    with open(state + '.json', 'r') as my_file:\n",
    "        json_data = my_file.read()\n",
    "        this = json.loads(json_data)\n",
    "    \n",
    "    s = 0 #sanders\n",
    "    w = 0 #warren\n",
    "    b = 0 #biden\n",
    "    \n",
    "    for i in this[state]:\n",
    "        if '@BernieSanders' in i['text'] and '@ewarren' in i['text'] and '@JoeBiden' in i['text']:\n",
    "            s += 1\n",
    "            w += 1\n",
    "            b +=1\n",
    "        \n",
    "        elif '@BernieSanders' in i['text'] and '@ewarren' in i['text']:\n",
    "            s += 1\n",
    "            w += 1\n",
    "        \n",
    "        elif '@JoeBiden' in i['text'] and '@ewarren' in i['text']:\n",
    "            b += 1\n",
    "            w += 1\n",
    "        \n",
    "        elif '@BernieSanders' in i['text'] and '@JoeBiden' in i['text']:\n",
    "            s += 1 \n",
    "            b += 1\n",
    "        \n",
    "        elif '@BernieSanders' in i['text']:\n",
    "            s += 1 \n",
    "        \n",
    "        elif '@ewarren' in i['text']:\n",
    "            w += 1 \n",
    "        \n",
    "        elif '@JoeBiden' in i['text']:\n",
    "            b +=1 \n",
    "    df.loc[num] = [state, b, s, w]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the inplementation of the function and the filenames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, t in enumerate(state):\n",
    "    input_state(t, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reset index can be used to change the index if the num increments are incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Sanders</th>\n",
       "      <th>Warren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DE</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FL</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GA</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HI</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IL</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IA</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KS</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KY</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LA</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ME</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MD</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MI</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MN</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MS</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MO</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MT</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NE</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NV</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NH</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NJ</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NM</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NY</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NC</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ND</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OH</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OK</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OR</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PA</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RI</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SC</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SD</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TN</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TX</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>UT</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VT</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VA</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WA</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>WV</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WI</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WY</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Biden Sanders Warren\n",
       "0     AK     0       0      0\n",
       "1     AL    62      15     19\n",
       "2     AR    67      26      6\n",
       "3     AZ    64      14     20\n",
       "4     CA    40      42     17\n",
       "5     CO    36      53      8\n",
       "6     CT    18      75      4\n",
       "7     DE    60      27     13\n",
       "8     FL    63      21     13\n",
       "9     GA    52      29     20\n",
       "10    HI    46      36     21\n",
       "11    ID    26      21     25\n",
       "12    IL    41      24     28\n",
       "13    IN     2      98      0\n",
       "14    IA     5      50      3\n",
       "15    KS    24      62      4\n",
       "16    KY    50      35     14\n",
       "17    LA    68      18      6\n",
       "18    ME    40      46     14\n",
       "19    MD    47      35      7\n",
       "20    MA     1       4     92\n",
       "21    MI    28      63     21\n",
       "22    MN    54      38      7\n",
       "23    MS    81       9      8\n",
       "24    MO    57      20     22\n",
       "25    MT    31       6      5\n",
       "26    NE    20      11      5\n",
       "27    NV    97       1      2\n",
       "28    NH     4      67     22\n",
       "29    NJ    25      43     15\n",
       "30    NM    29      21     16\n",
       "31    NY    70      23      6\n",
       "32    NC    52      30     18\n",
       "33    ND    54      37      9\n",
       "34    OH    41      24      6\n",
       "35    OK    60      26      7\n",
       "36    OR    48      44      9\n",
       "37    PA    64      20     10\n",
       "38    RI    32      20     45\n",
       "39    SC    43      26     20\n",
       "40    SD    46      38     19\n",
       "41    TN    58      27     15\n",
       "42    TX    51      11     10\n",
       "43    UT    36      22      9\n",
       "44    VT    10      63     13\n",
       "45    VA    25      43     15\n",
       "46    WA    44      20     20\n",
       "47    WV    71      19      8\n",
       "48    WI    47      26     25\n",
       "49    WY     4       2      9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row contains information of each state and how many tweets mentions each candidate. I wanted to add a row total to examine the candidate with the most tweets over all. But either way, the table allows a good visualization of the tweets per state and overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Biden</th>\n",
       "      <th>Sanders</th>\n",
       "      <th>Warren</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CT</td>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DE</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FL</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GA</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HI</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IL</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IN</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IA</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KS</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KY</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LA</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ME</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MD</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MI</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MN</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MS</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MO</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MT</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NE</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NV</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NH</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NJ</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NM</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NY</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NC</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ND</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OH</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OK</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OR</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PA</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RI</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SC</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SD</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TN</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TX</td>\n",
       "      <td>51</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>UT</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>VT</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VA</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>WA</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>WV</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>WI</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WY</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2094</td>\n",
       "      <td>1531</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Biden Sanders Warren\n",
       "0        AK     0       0      0\n",
       "1        AL    62      15     19\n",
       "2        AR    67      26      6\n",
       "3        AZ    64      14     20\n",
       "4        CA    40      42     17\n",
       "5        CO    36      53      8\n",
       "6        CT    18      75      4\n",
       "7        DE    60      27     13\n",
       "8        FL    63      21     13\n",
       "9        GA    52      29     20\n",
       "10       HI    46      36     21\n",
       "11       ID    26      21     25\n",
       "12       IL    41      24     28\n",
       "13       IN     2      98      0\n",
       "14       IA     5      50      3\n",
       "15       KS    24      62      4\n",
       "16       KY    50      35     14\n",
       "17       LA    68      18      6\n",
       "18       ME    40      46     14\n",
       "19       MD    47      35      7\n",
       "20       MA     1       4     92\n",
       "21       MI    28      63     21\n",
       "22       MN    54      38      7\n",
       "23       MS    81       9      8\n",
       "24       MO    57      20     22\n",
       "25       MT    31       6      5\n",
       "26       NE    20      11      5\n",
       "27       NV    97       1      2\n",
       "28       NH     4      67     22\n",
       "29       NJ    25      43     15\n",
       "30       NM    29      21     16\n",
       "31       NY    70      23      6\n",
       "32       NC    52      30     18\n",
       "33       ND    54      37      9\n",
       "34       OH    41      24      6\n",
       "35       OK    60      26      7\n",
       "36       OR    48      44      9\n",
       "37       PA    64      20     10\n",
       "38       RI    32      20     45\n",
       "39       SC    43      26     20\n",
       "40       SD    46      38     19\n",
       "41       TN    58      27     15\n",
       "42       TX    51      11     10\n",
       "43       UT    36      22      9\n",
       "44       VT    10      63     13\n",
       "45       VA    25      43     15\n",
       "46       WA    44      20     20\n",
       "47       WV    71      19      8\n",
       "48       WI    47      26     25\n",
       "49       WY     4       2      9\n",
       "Total   NaN  2094    1531    730"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"Total\"] = df.iloc[:,1:4].sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it seems that Joe Biden has the most tweets from all 50 states. Whether or not these tweets are positive or negative I believe that this project can be expanded after learning more concepts about natural processing language and tokenization. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
